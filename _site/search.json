[
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html",
    "title": "Handson_Ex03",
    "section": "",
    "text": "Load packages and data:\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse)\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called *tooltip*. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\nexam_data$tooltip <- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nCustomize toolpit:\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)    \n\n\n\n\n\nIn this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n) \n\n\n\n\n\nHighlighting effect:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n) \n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)  \n\n\n\n\n\n`onclick` argument of ggiraph provides hotlink interactivity on the web.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)     \n\n\n\n\n\n\n\n\n1. Appropriate interactive functions of **ggiraph** will be used to create the multiple views.\n2. *patchwork* function of [patchwork](https://patchwork.data-imaginist.com/) package will be used inside girafe function to create the interactive coordinated multiple views.\n\np1 <- ggplot(data=exam_data, \n           aes(x = MATHS)) +\n      geom_dotplot_interactive(              \n        aes(data_id = ID),              \n        stackgroups = TRUE,                  \n        binwidth = 1,                        \n        method = \"histodot\") +  \n      coord_cartesian(xlim=c(0,100)) + \n      scale_y_continuous(NULL,               \n                         breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n           aes(x = ENGLISH)) +\n      geom_dotplot_interactive(              \n        aes(data_id = ID),              \n        stackgroups = TRUE,                  \n        binwidth = 1,                        \n        method = \"histodot\") + \n      coord_cartesian(xlim=c(0,100)) + \n      scale_y_continuous(NULL,               \n                         breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n           width_svg = 6,\n           height_svg = 3,\n           options = list(\n             opts_hover(css = \"fill: #202020;\"),\n             opts_hover_inv(css = \"opacity:0.2;\")\n             )\n           ) \n\n\n\n\n\nCreating an interactive scatter plot: plot_ly() method\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n- [`highlight_key()`](https://www.rdocumentation.org/packages/plotly/versions/4.9.2/topics/highlight_key) of **plotly** package is used as shared data.\n- two scatterplots will be created by using ggplot2 functions.\n- lastly, [*subplot()*](https://plotly.com/r/subplots/) of **plotly** package is used to place them next to each other side-by-side.\n\nd <- highlight_key(exam_data)\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\nInteractive Data Table: DT package\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 6)"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Handson_Ex03",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#animated-data-visualization-plotly",
    "href": "Handson_Ex/Handson_Ex03/Handson_Ex03.html#animated-data-visualization-plotly",
    "title": "Handson_Ex03",
    "section": "Animated Data Visualization: plotly",
    "text": "Animated Data Visualization: plotly\n\ngg <- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\nbp <- globalPop %>%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent, \n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          )\nbp"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex04/Handson_Ex04.html",
    "href": "Handson_Ex/Handson_Ex04/Handson_Ex04.html",
    "title": "Handson_Ex04",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam <-read.csv(\"data/Exam_data.csv\")\n\n\n\nType of statistic expected (\"parametric\" or \"nonparametric\" or \"robust\" or \"bayes\").Corresponding abbreviations are also accepted: \"p\" (for parametric), \"np\" (nonparametric), \"r\" (robust), or \"bf\"resp.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)          \n\n\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale       \n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   <dbl> <chr>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>         <dbl>  <dbl>\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period <dbl>, HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n\n\n\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\n\ncheck_h <- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Handson_Ex04",
    "section": "Visualizing the uncertainty of point estimates",
    "text": "Visualizing the uncertainty of point estimates\nImport packages and data\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by race\")\n\n\n\n\nPlot the 95% confidence interval of mean maths score by race. The error bars should be sorted by the average maths scores.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-qt(0.025,df=n,lower.tail = FALSE)*se, \n        ymax=mean+qt(0.025,df=n,lower.tail = FALSE)*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=reorder(RACE, -mean), \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates with interactive error bars\n\nd <- highlight_key(my_sum) \np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-qt(0.01,df=n,lower.tail = FALSE)*se, \n        ymax=mean+qt(0.01,df=n,lower.tail = FALSE)*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=reorder(RACE, -mean), \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"99% confidence interval of mean maths score by race\")\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 6)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.99,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#visualizing-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Handson_Ex04",
    "section": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\nImport packages\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Handson_Ex/Handson_Ex04/Handson_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Handson_Ex04",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\n\nComputing the basic derived field\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex05/Handson_Ex05.html",
    "href": "Handson_Ex/Handson_Ex05/Handson_Ex05.html",
    "title": "Handson_Ex05",
    "section": "",
    "text": "Show the code\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\n\n\nShow the code\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\n\nShow the code\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\n\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\n\nShow the code\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\n\n\nShow the code\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\n\n\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)       \n\n\n\n\n\n\n\n\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)      \n\n\n\n\n\n\n\n\n\n\nShow the code\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\n\nShow the code\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nShow the code\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\n\nShow the code\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nYou can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nYou can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n\n\n\n\nShow the code\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex07/Handson_Ex07.html",
    "href": "Handson_Ex/Handson_Ex07/Handson_Ex07.html",
    "title": "Handson_Ex07",
    "section": "",
    "text": "Show the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nImport eventlog.csv file into R environment and called the data frame as attacks.\n\n\nShow the code\n#Reading the data into R environment\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\n\n\n\n\nShow the code\nkable(head(attacks))\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\nStep 1: Deriving weekday and hour of day fields\n\n\nShow the code\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nShow the code\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n\nNotes\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they'll be ordered when plotting\n\n\nFinal check:\n\n\nShow the code\nkable(head(attacks))\n\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\n\nShow the code\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\n\n\nShow the code\n#plot a cluster heatmap\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\n\nShow the code\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\n\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\n\nShow the code\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()    \n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\n\nShow the code\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )  \n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\nDeriving month and year fields\n\n\nShow the code\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\nExtracting the target country\n\n\nShow the code\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\nComputing year average arrivals by month\n\n\nShow the code\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\n\n\n\nShow the code\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")\n\n\n\n\n\n\n\n\n\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\n\n\nShow the code\nrice <- read_csv(\"data/rice.csv\")\n\n\n\n\n\n\n\nShow the code\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor.\n\n\n\n\n\n\nLoading packages:\n\n\nShow the code\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\n\n\nShow the code\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`))\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nBy default, read_csv will import data in Date field as Character data type. dmy() of lubridate package to palse the Date field into appropriate Date data type in R.\n\n\n\n\n\n\n\n\nShow the code\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex01/Handson_Ex01.html",
    "href": "Handson_Ex/Handson_Ex01/Handson_Ex01.html",
    "title": "Handson_Ex01",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <-read.csv(\"data/Exam_data.csv\")\n\n\n\n\n\nhist(exam_data$MATHS)\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex06/Handson_Ex06.html",
    "href": "Handson_Ex/Handson_Ex06/Handson_Ex06.html",
    "title": "Handson_Ex06",
    "section": "",
    "text": "Show the code\npacman::p_load('plotly', 'tidyverse')\n\n\n\n\nShow the code\n#require(devtools)\n#install_version(\"ggtern\", version = \"3.4.1\")\n\n\n\n\nShow the code\n#library(ggtern)\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\nShow the code\n#Reading the data into R environment\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\n\n\n\nShow the code\n#Deriving the young, economy active and old measures\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\n\n\n\n\nShow the code\n#Building the static ternary plot\n#ggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n#  geom_point()\n\n\n\n\nShow the code\n#Building the static ternary plot\n#ggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n#  geom_point() +\n#  labs(title=\"Population structure, 2015\") +\n#  theme_rgbw()\n\n\n\n\n\n\n\nShow the code\n# reusable function for creating annotation object\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex06/Handson_Ex06.html#visual-multivariate-analysis-with-parallel-coordinates-plot",
    "href": "Handson_Ex/Handson_Ex06/Handson_Ex06.html#visual-multivariate-analysis-with-parallel-coordinates-plot",
    "title": "Handson_Ex06",
    "section": "Visual Multivariate Analysis with Parallel Coordinates Plot",
    "text": "Visual Multivariate Analysis with Parallel Coordinates Plot\nParallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), \"This certainly isn't a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn't in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.\" For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\nPackages\n\n\nShow the code\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nData preparation\n\n\nShow the code\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nPlotting Static Parallel Coordinates Plot\nPlotting a simple parallel coordinates\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\nPlotting a parallel coordinates with boxplot\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\nParallel coordinates with facet\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\nRotating x-axis text label\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\nAdjusting the rotated x-axis text label\n\n\nShow the code\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))\n\n\n\n\n\n\n\nPlotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using 'htmlwidgets' package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\nThe basic plot\n\n\nShow the code\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\nRotate axis label\n\n\nShow the code\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\nChanging the colour scheme\n\n\nShow the code\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\nParallel coordinates plot with histogram\n\n\nShow the code\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Handson_Ex/Handson_Ex06/Handson_Ex06.html#treemap-visualisation-with-r",
    "href": "Handson_Ex/Handson_Ex06/Handson_Ex06.html#treemap-visualisation-with-r",
    "title": "Handson_Ex06",
    "section": "Treemap Visualisation with R",
    "text": "Treemap Visualisation with R\n\nPackages\n\n\nShow the code\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nData wrangling\n\n\nShow the code\nrealis2018 <- read_csv(\"data/realis2018.csv\")\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they'll be automatically applied \"by group\".\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(\"window-functions\").\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\n\n\nShow the code\nrealis2018_grouped <- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised <- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\nShow the code\nrealis2018_summarised <- realis2018 %>% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %>%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\nDesigning Treemap with treemap Package\nDesigning a static treemap\n\n\nShow the code\nrealis2018_selected <- realis2018_summarised %>%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\nUsing basic arguments\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it's vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\nShow the code\n#Working with vColor and type arguments\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nValue type treemap\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\nManual type treemap\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nWorking with algorithm argument\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nUsing sortID\n\n\nShow the code\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nDesigning Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to \"treemapify\" its user guide.\n\n\nShow the code\n#basic treemap\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\nShow the code\n#defining hierarchy\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\nShow the code\n#Groupping by planning area\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\nShow the code\n#adding boundary line\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")\n\n\n\n\n\n\n\nDesigning Interactive Treemap using d3treeR\n\n\nShow the code\nlibrary(d3treeR)\n\n\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\n\nShow the code\ntm <- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\n\nShow the code\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "This is the website for ISSS608 Visual Analytics and Applications."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home_Ex01",
    "section": "",
    "text": "City of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards. The local council of the city is in the process of preparing the Local Plan 2023. A sample survey of 1000 representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received.\n\n\n\nFor the purpose of this study, two data sets are provided. They are:\nParticipants.csv\nContains information about the residents of City of Engagement that have agreed to participate in this study.\n\nparticipantId (integer): unique ID assigned to each participant.\nhouseholdSize (integer): the number of people in the participant’s household\nhaveKids (boolean): whether there are children living in the participant’s household.\nage (integer): participant’s age in years at the start of the study.\neducationLevel (string factor): the participant’s education level, one of: {“Low”, “HighSchoolOrCollege”, “Bachelors”, “Graduate”}\ninterestGroup (char): a char representing the participant’s stated primary interest group, one of {“A”, “B”, “C”, “D”, “E”, “F”, “G”, “H”, “I”, “J”}. Note: specific topics of interest have been redacted to avoid bias.\njoviality (float): a value ranging from [0,1] indicating the participant’s overall happiness level at the start of the study.\n\nFinancialJournal.csv\nContains information about financial transactions.\n\nparticipantId (integer): unique ID corresponding to the participant affected\ntimestamp (datetime): the time when the check-in was logged\ncategory (string factor): a string describing the expense category, one of {“Education”, “Food”, “Recreation”, “RentAdjustment”, “Shelter”, “Wage”}\namount (double): the amount of the transaction\n\nFor explanation of Rent Adjustment, please refer to this link."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages-and-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages-and-data",
    "title": "Take-home_Ex01",
    "section": "2. Load packages and data:",
    "text": "2. Load packages and data:\nThe data should be processed by using appropriate tidyverse family of packages and the statistical graphics must be prepared using ggplot2 and its extensions.\n\n\nShow the code\npacman::p_load(ggstatsplot, tidyverse, ggplot2, plotly, ggmosaic, ggridges, gganimate,ggdist)\n\nfi <- read.csv(\"data/FinancialJournal.csv\")\nparti <- read.csv(\"data/Participants.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-checkingcleaning",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-checkingcleaning",
    "title": "Take-home_Ex01",
    "section": "3. Data checking/cleaning:",
    "text": "3. Data checking/cleaning:\n\n3.1 Check the summary of tables to get a whole picture of the data:\n\n\nShow the code\nsummary(fi)\n\n\n participantId     timestamp           category             amount         \n Min.   :   0.0   Length:1513636     Length:1513636     Min.   :-1562.726  \n 1st Qu.: 222.0   Class :character   Class :character   1st Qu.:   -5.594  \n Median : 464.0   Mode  :character   Mode  :character   Median :   -4.000  \n Mean   : 480.9                                         Mean   :   20.047  \n 3rd Qu.: 726.0                                         3rd Qu.:   21.598  \n Max.   :1010.0                                         Max.   : 4096.526  \n\n\nShow the code\nsummary(parti)\n\n\n participantId    householdSize    haveKids            age       \n Min.   :   0.0   Min.   :1.000   Mode :logical   Min.   :18.00  \n 1st Qu.: 252.5   1st Qu.:1.000   FALSE:710       1st Qu.:29.00  \n Median : 505.0   Median :2.000   TRUE :301       Median :39.00  \n Mean   : 505.0   Mean   :1.964                   Mean   :39.07  \n 3rd Qu.: 757.5   3rd Qu.:3.000                   3rd Qu.:50.00  \n Max.   :1010.0   Max.   :3.000                   Max.   :60.00  \n educationLevel     interestGroup        joviality       \n Length:1011        Length:1011        Min.   :0.000204  \n Class :character   Class :character   1st Qu.:0.240074  \n Mode  :character   Mode  :character   Median :0.477539  \n                                       Mean   :0.493794  \n                                       3rd Qu.:0.746819  \n                                       Max.   :0.999234  \n\n\n\n\n3.2 Some further check on each table\n\n\n3.2.1 Further check of fi table by summarizing by categories:\n\nIt’s confirmed from the summary table that “wages” and “rent adjustment” got only positive numbers and other categories are negative numbers.\n\n\n\nShow the code\nfi$month <- months.Date(strptime(fi$timestamp, \"%Y-%m-%d\"))\nfi$year <- format(strptime(fi$timestamp, \"%Y-%m-%d\"), format=\"%Y\")\nfi$yearmonth <- paste(fi$year,fi$month)\n\nfi %>%\n  group_by(year, category) %>%\n  summarise(median = median(amount),\n            mean = mean(amount),\n            min = min(amount),\n            max = max(amount),\n            n = n(),\n            neg = sum(amount<0))\n\n\n# A tibble: 11 × 8\n# Groups:   year [2]\n   year  category       median    mean       min      max      n    neg\n   <chr> <chr>           <dbl>   <dbl>     <dbl>    <dbl>  <int>  <int>\n 1 2022  Education       -38.0  -46.6    -91.1    -12.8     2825   2825\n 2 2022  Food             -4     -4.69   -14.8     -4     662378 662378\n 3 2022  Recreation      -14.4  -14.0    -44.5     -0.535 254501 254501\n 4 2022  RentAdjustment  246.   419.      77.2   1506.       131      0\n 5 2022  Shelter        -659.  -638.   -1563.    -232.      9703   9703\n 6 2022  Wage             83.9  112.       0.833 4097.    346531      0\n 7 2023  Education       -38.0  -46.2    -91.1    -12.8      494    494\n 8 2023  Food             -4     -4.67   -14.8     -4     127673 127673\n 9 2023  Recreation      -14.4  -14.0    -44.5     -0.535  41512  41512\n10 2023  Shelter        -654.  -635.   -1556.    -232.      1760   1760\n11 2023  Wage             83.9  105.       0.833  664.     66128      0\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHere the Rent Adjustment amount which have much less N of records compare to other categories need to be carefully treated.\n\n\n\n\n3.2.2 Further check of parti table:\n\nDistribution of joviality:\n\n\nShow the code\nd <- highlight_key(parti)\np <-ggplot(data=parti, aes(x = joviality)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"white\", \n                 fill=\"#4575B4\") +\n  theme_light()+\n  ggtitle(\"Distribution of joviality\")\n\nhighlight(ggplotly(p),\"plotly_selected\")  \n\n\n\n\n\n\nDistribution of other variables:\n\n\nShow the code\nd <- highlight_key(parti)\np1 <- ggplot(data=d, aes(x = householdSize)) +\n  geom_bar(stat = \"count\", \n           boundary = 100,\n           color=\"white\", \n           fill=\"#4575B4\") +\n  xlab(\"Household Size\")\n\np2 <- ggplot(data=d, aes(x = age)) +\n  geom_bar(stat = \"count\", \n           boundary = 100,\n           color=\"white\", \n           fill=\"#ABD9E9\") +\n  xlab(\"Age\")\n\np3 <- ggplot(data=d, aes(x = educationLevel)) +\n  geom_bar(stat = \"count\", \n           boundary = 100,\n           color=\"white\", \n           fill=\"#FEE090\") +\n  xlab(\"Education Level\")+\n  theme(axis.text.x = element_text(angle = 30))\n\np4 <- ggplot(data=d, aes(x = interestGroup)) +\n  geom_bar(stat = \"count\", \n           boundary = 100,\n           color=\"white\", \n           fill=\"#F46D43\") +\n  xlab(\"Interest Group\")\n\nsubplot(ggplotly(p1),\n        ggplotly(p2),\n        ggplotly(p3),\n        ggplotly(p4),\n        nrows = 2,\n        titleX = TRUE,\n        margin = 0.1)\n\n\n\n\n\n\n\n\n\n3.3 Combine information into one table\n\nFind monthly average income and expenses of each participant ID;\nRe-categorize wage as “Income”, and all others together as “Expenses”;\nAnd for the convenience of latter using, I will create a column named “absave” to save the absolute number of the amount.\n\n\n\nShow the code\nfi_ave_by_cat <- fi%>%\n  group_by(participantId, category) %>%\n  summarise(total_amount = sum(amount),\n            n_months = length(unique(yearmonth)))\nfi_ave_by_cat$ave = ifelse(fi_ave_by_cat$category == 'RentAdjustment', \n                           fi_ave_by_cat$total_amount/12, \n                           fi_ave_by_cat$total_amount/fi_ave_by_cat$n_months)\n\nfi_ave_by_cat$bicat <- ifelse(fi_ave_by_cat$category == 'Wage','Income', 'Expenses')\nfi_ave_by_cat$absave <- abs(fi_ave_by_cat$ave)\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere I divided the amount of “Rent Adjustment” by 12 rather than the unique months of it’s record, that’s because this amount is an annual amount occurred only once in a year.\n\n\n\nThen summarize into a new table named “fi_ave” in which transpose the monthly average Income/Expenses categories into column names;\n\n\n\nShow the code\nfi_ave <- fi_ave_by_cat%>%\n  group_by(participantId, bicat) %>%\n  summarise(mon_ave = abs(sum(ave))) %>%\n  pivot_wider(names_from = bicat,values_from = mon_ave, names_prefix = \"mon_ave_\")\n\n\n\nCombine “fi_ave” with “parti” into a new table named “joy”.\n\n\n\nShow the code\njoy <- full_join(fi_ave,parti,by=\"participantId\")\nsummary(joy)\n\n\n participantId    mon_ave_Expenses mon_ave_Income  householdSize  \n Min.   :   0.0   Min.   :  32     Min.   : 1904   Min.   :1.000  \n 1st Qu.: 252.5   1st Qu.:1096     1st Qu.: 2563   1st Qu.:1.000  \n Median : 505.0   Median :1401     Median : 3416   Median :2.000  \n Mean   : 505.0   Mean   :1282     Mean   : 4061   Mean   :1.964  \n 3rd Qu.: 757.5   3rd Qu.:1650     3rd Qu.: 4805   3rd Qu.:3.000  \n Max.   :1010.0   Max.   :2713     Max.   :17645   Max.   :3.000  \n  haveKids            age        educationLevel     interestGroup     \n Mode :logical   Min.   :18.00   Length:1011        Length:1011       \n FALSE:710       1st Qu.:29.00   Class :character   Class :character  \n TRUE :301       Median :39.00   Mode  :character   Mode  :character  \n                 Mean   :39.07                                        \n                 3rd Qu.:50.00                                        \n                 Max.   :60.00                                        \n   joviality       \n Min.   :0.000204  \n 1st Qu.:0.240074  \n Median :0.477539  \n Mean   :0.493794  \n 3rd Qu.:0.746819  \n Max.   :0.999234"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-demographic-characteristics-of-the-city",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-demographic-characteristics-of-the-city",
    "title": "Take-home_Ex01",
    "section": "4.1 Finding demographic characteristics of the city",
    "text": "4.1 Finding demographic characteristics of the city\n\n4.1.1 How interest group varies by education levels?\nFrom the chart below we can find that different interest group attract people with quite different education level.\n\n\nShow the code\nd <- highlight_key(joy)\np <- ggplot(data = joy) +\n  geom_mosaic(aes(x = product(interestGroup), fill= educationLevel)) +\n  theme_mosaic() +\n  scale_fill_manual(values = c(\"#4575B4\", \"#ABD9E9\", \"#FEE090\", \"#F46D43\"))+\n  xlab(\"\")+\n  ylab(\"\")\n\nhighlight(ggplotly(p),\"plotly_selected\")  \n\n\n\n\n\n\n\n\n4.1.2 How interest group changes with people’s age?\n\n\nShow the code\nggplot(joy, aes(x = age, y = interestGroup, fill = interestGroup)) +\n  geom_density_ridges(alpha=0.8, color = \"white\") +\n  theme_ridges() + \n  theme(legend.position = \"none\",\n        panel.spacing = unit(0.1, \"lines\"),\n        strip.text.x = element_text(size = 8))+\n  scale_fill_manual(values = c(\"#F4EDCA\",\"#E7B800\", \"#C4961A\",  \"#D16103\", \"#C3D7A4\", \"#52854C\", \"#4E84C4\", \"#ABD9E9\", \"#FEE090\", \"#F46D43\")) +\n  xlab(\"Age\") +\n  ylab(\"Interest Groups\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-financial-characteristics-of-the-city",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-financial-characteristics-of-the-city",
    "title": "Take-home_Ex01",
    "section": "4.2 Finding financial characteristics of the city",
    "text": "4.2 Finding financial characteristics of the city\n\n4.2.1 How monthly average income varies between different education level groups\nCitizens’ monthly income apparently goes up with their educational level, indicating local labor market do care about employees’ education background.\n\n\nShow the code\nggbetweenstats(\n  data = joy,\n  x = educationLevel, \n  y = mon_ave_Income,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n4.2.2 Looks into monthly average income’s distribution together with other demographic information\nMonthly income distributing quite evenly over different household size and joviality level.\n\n\nShow the code\nd <- highlight_key(joy)\np <- ggplot(joy, aes(x = mon_ave_Income, y = joviality, \n                      size = householdSize, \n                      colour = haveKids)) +\n  geom_point(alpha = 0.6) +\n  scale_colour_manual(values = c(\"#4E84C4\", \"#FEE090\")) +\n  scale_size(range = c(1, 3))+\n  labs(title = 'Do people earn more feel happier?', \n       x = 'Monthly average income', \n       y = 'Joviality')\n\nhighlight(ggplotly(p),\"plotly_selected\")  \n\n\n\n\n\n\n\n\n4.2.3 How monthly expenses varies between different household size\nThe amount of monthly expenses of single household is quite different from other household size.\n\n\nShow the code\nggbetweenstats(\n  data = joy,\n  x = householdSize, \n  y = mon_ave_Expenses,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n4.2.4 Looks into monthly average expenses by categories\nAnd people’s most big amount of expense seems to be shelter expenses.\n\n\nShow the code\nfi_ave_by_cat %>%\n  filter(bicat != \"Income\" & category != \"RentAdjustment\") %>%\n  ggplot(aes(x = category, y = absave)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  theme_light() +\n  labs(\n    title = \"Confidence intervals of mean expense by category\",\n    subtitle = \"Mean Point + Multiple-interval plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-correlation-between-characteristics-and-joviality",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#finding-correlation-between-characteristics-and-joviality",
    "title": "Take-home_Ex01",
    "section": "4.3 Finding correlation between characteristics and joviality",
    "text": "4.3 Finding correlation between characteristics and joviality\n\n4.3.1 Do people earn more feel happier?\nNo matter we look into the correlation between joviality and monthly income as a whole or by educational level group, the correlation is relatively week.\n\n\nShow the code\nggscatterstats(data = joy,\n                     x = mon_ave_Income,\n                     y = joviality,\n                     marginal = FALSE,\n                     point.args = list(size = 1, alpha = 0.6, stroke = 0),\n               title = \"Joviality negatively correlated with monthly average income\")\n\n\n\n\n\n\n\nShow the code\ngrouped_ggscatterstats(\n  data = joy,\n  x = mon_ave_Income,\n  y = joviality,\n  marginal = FALSE,\n  point.args = list(size = 1, alpha = 0.6, stroke = 0),\n  grouping.var = educationLevel,\n  type = \"r\",\n  annotation.args = list(title = \"Relationship between joviality and income by education level\"),\n  plotgrid.args = list(nrow = 2, ncol = 2)\n)\n\n\n\n\n\n\n\n4.3.2 Or do people spend more feel happier?\n\nTo look at the correlation between joviality and monthly average expenses, seemingly there is only a weakly positive correlation.\n\n\n\nShow the code\nggscatterstats(data = joy,\n                    x = mon_ave_Expenses,\n                    y = joviality,\n                    marginal = FALSE,\n                    point.args = list(size = 1, alpha = 0.6, stroke = 0),\n               title = \"Joviality positively correlated with monthly average expenses\")\n\n\n\n\n\n\nFunny part is, when we look at this correlation by different household size, the correlation between joviality and monthly average expenses is much stronger for size 1 households, indicating single persons enjoy spending money!\n\n\n\nShow the code\ngrouped_ggscatterstats(\n  ## arguments relevant for ggscatterstats\n  data = joy,\n  x = mon_ave_Expenses,\n  y = joviality,\n  marginal = FALSE,\n  point.args = list(size = 1, alpha = 0.6, stroke = 0),\n  grouping.var = householdSize,\n  type = \"r\", \n  annotation.args = list(title = \"Relationship between joviality and expenses by household size\"),\n  plotgrid.args = list(nrow = 1)\n)\n\n\n\n\n\n\nThen let’s dig deeper to see how single person’s spend their money.\nUnlike what we have seen in analysis of whole data set which indicating people spend the most on shelter, the average amount single citizens spend on food and recreation comes much closer to the average amount spend on shelter.\n\n\nShow the code\nsingleId <- joy %>%\n  filter(householdSize == 1) %>%\n  subset(select = \"participantId\")\n\nexpense_cat <- fi_ave_by_cat%>%\n  filter(bicat == \"Expenses\" & category != \"RentAdjustment\") %>%\n  subset(select = c(\"participantId\", \"category\", \"absave\")) %>%\n  group_by(participantId, category) %>%\n  summarise(absave = sum(absave))\n\nsingle <- left_join(singleId, expense_cat, by = \"participantId\")\n\nsingle %>%\n  ggplot(aes(x = category, y = absave)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  theme_light() +\n  labs(\n    title = \"Confidence intervals of single citizens' mean expense by category\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nIf this is the case, do person’s joviality correlated with their spending on recreation?\nYes, they do!\n\n\nShow the code\njoy_withcat <- left_join(joy, \n                 expense_cat %>% pivot_wider(names_from = category, names_prefix = \"mon_ave_\", values_from = absave),\n                 by = \"participantId\")\n\nggscatterstats(data = joy_withcat,\n                    x = mon_ave_Recreation,\n                    y = joviality,\n                    marginal = FALSE,\n                    point.args = list(size = 1, alpha = 0.6, stroke = 0),\n               title = \"Joviality positively correlated with monthly average spending on recreation\")\n\n\n\n\n\nHow about expenses on food?\nNo, they don’t.\n\n\nShow the code\nggscatterstats(data = joy_withcat,\n                    x = mon_ave_Food,\n                    y = joviality,\n                    marginal = FALSE,\n                    point.args = list(size = 1, alpha = 0.6, stroke = 0),\n               title = \"Joviality positively correlated with monthly average spending on recreation\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "FishEye International, a non-profit focused on countering illegal, unreported, and unregulated (IUU) fishing, has been given access to an international finance corporation’s database on fishing related companies. In the past, FishEye has determined that companies with anomalous structures are far more likely to be involved in IUU (or other “fishy” business). FishEye has transformed the database into a knowledge graph. It includes information about companies, owners, workers, and financial status. FishEye is aiming to use this graph to identify anomalies that could indicate a company is involved in IUU.\nFishEye analysts have attempted to use traditional node-link visualizations and standard graph analyses, but these were found to be ineffective because the scale and detail in the data can obscure a business’s true structure. Can you help FishEye develop a new visual analytics approach to better understand fishing business anomalies?\n\n\n\nUse visual analytics to understand patterns of groups in the knowledge graph and highlight anomalous groups.\n\nUse visual analytics to identify anomalies in the business groups present in the knowledge graph. Limit your response to 400 words and 5 images.\nDevelop a visual analytics process to find similar businesses and group them. This analysis should focus on a business’s most important features and present those features clearly to the user. Limit your response to 400 words and 5 images.\nMeasure similarity of businesses that you group in the previous question. Express confidence in your groupings visually. Limit your response to 400 words and 4 images.\nBased on your visualizations, provide evidence for or against the case that anomalous companies are involved in illegal fishing. Which business groups should FishEye investigate further? Limit your response to 600 words and 6 images."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#find-the-nodes-and-edges",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#find-the-nodes-and-edges",
    "title": "Take-home_Ex03",
    "section": "3.1 Find the nodes and edges:",
    "text": "3.1 Find the nodes and edges:\n\n\nShow the code\n#view(mc2[[\"nodes\"]])\nmc3_nodes <- as_tibble(mc3$nodes) %>%\n  mutate(country=as.character(country),\n         id=as.character(id),\n         product_services=as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type=as.character(type)) %>%\n  select(id,country, type, revenue_omu, product_services) \n#  group_by(id,country, type, product_services) %>%\n#  summarise(count=n(),revenue=sum(revenue_omu))\n\n\n\n\nShow the code\n#view(mc2[[\"links\"]])\nmc3_edges <- as_tibble(mc3$links) %>%\n  distinct() %>%\n  mutate(source=as.character(source),\n         target=as.character(target),\n         type=as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weight=n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n\n\n\nShow the code\nglimpse(mc3_edges)\n\n\nRows: 24,036\nColumns: 4\n$ source <chr> \"1 AS Marine sanctuary\", \"1 AS Marine sanctuary\", \"1 Ltd. Liabi…\n$ target <chr> \"Christina Taylor\", \"Debbie Sanders\", \"Angela Smith\", \"Catherin…\n$ type   <chr> \"Company Contacts\", \"Beneficial Owner\", \"Beneficial Owner\", \"Co…\n$ weight <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\n\n\nShow the code\nmc3_edges %>%\n  select(type) %>%\n  group_by(type) %>%\n  summarise(count = n())\n\n\n# A tibble: 2 × 2\n  type             count\n  <chr>            <int>\n1 Beneficial Owner 16792\n2 Company Contacts  7244\n\n\n\n\nShow the code\nggplot(data = mc3_nodes, \n       aes(x=type)) +\n  geom_bar() +\n  xlab(\"Type\")+\n  ylab(\"Count\")\n\n\n\n\n\n\n\nShow the code\nmc3_nodes %>%\n  select(product_services) %>%\n  group_by(product_services) %>%\n  summarise(count = n())\n\n\n# A tibble: 3,244 × 2\n   product_services                                                        count\n   <chr>                                                                   <int>\n 1 (Italian) peeled tomatoes, legumes, vegetables, fruits and canned mush…     1\n 2 100 percent Spanish olives; peppers, green, black, and manzanilla stuf…     1\n 3 2 or 3-piece containers, twist off caps, easy opening and traditional …     1\n 4 8 Cement Mixer Units, Ocean Freight, Air Freight, Project Logistics, C…     1\n 5 A chemical science firm with a focus on the development of high purity…     1\n 6 A complete range of fully-vertical, Schiffli embroidery manufacturing …     1\n 7 A complete range of transportation and logistics services                   1\n 8 A customs broker and freight forwarder                                      1\n 9 A distributor, importer and exporter of food products to the food reta…     1\n10 A freight broker                                                            1\n# ℹ 3,234 more rows\n\n\n\n\n\n\n\n\nNote:\n\n\n\nHere before we do text analysis on product services, some stopwords like “character(0)” need to be treated."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-attributes",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#wrangling-attributes",
    "title": "Take-home_Ex03",
    "section": "3.2 Wrangling attributes:",
    "text": "3.2 Wrangling attributes:\n\nFind hscode with most edges and hscode with most weightkg of fishing:\n\n\nShow the code\nmc3_nodes %>%\n  mutate(n_fish = str_count(product_services), \"fish\")\n\n\n# A tibble: 27,622 × 7\n   id                 country type  revenue_omu product_services n_fish `\"fish\"`\n   <chr>              <chr>   <chr>       <dbl> <chr>             <int> <chr>   \n 1 Jones LLC          ZH      Comp…  310612303. Automobiles          11 fish    \n 2 Coleman, Hall and… ZH      Comp…  162734684. Passenger cars,…     39 fish    \n 3 Aqua Advancements… Oceanus Comp…  115004667. Holding firm wh…    248 fish    \n 4 Makumba Ltd. Liab… Utopor… Comp…   90986413. Car service, ca…    428 fish    \n 5 Taylor, Taylor an… ZH      Comp…   81466667. Fully electric …     72 fish    \n 6 Harmon, Edwards a… ZH      Comp…   75070435. Discount superm…     59 fish    \n 7 Punjab s Marine c… Riodel… Comp…   72167572. Beef, pork, chi…    652 fish    \n 8 Assam   Limited L… Utopor… Comp…   72162317. Power and Gas s…   1737 fish    \n 9 Ianira Starfish S… Rio Is… Comp…   68832979. Light commercia…     94 fish    \n10 Moran, Lewis and … ZH      Comp…   65592906. Automobiles, tr…     88 fish    \n# ℹ 27,612 more rows\n\n\n\nWord tokenization with punctuation and no lowercasing\n\n\nShow the code\ntidy_nodes <- mc3_nodes %>%\n  unnest_tokens(word, product_services, to_lower = TRUE, strip_punct = TRUE)\n\n\nRemoving stop words\n\n\nShow the code\ntidy_stopwords <- tidy_nodes %>%\n  anti_join(stop_words) #%>%\n#  anti_join(by = c(\"character\",\"0\",\"unknown\"))\n\n\n\nDistribution of fishing weight (kg) by years:\n\n\n\n\n\nDistribution of number of edges by years:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-temporal-patterns-for-individual-entities-by-heatmap",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-temporal-patterns-for-individual-entities-by-heatmap",
    "title": "Take-home_Ex03",
    "section": "4.1 Visualizing temporal patterns for individual entities by heatmap",
    "text": "4.1 Visualizing temporal patterns for individual entities by heatmap\n\n4.1.1 Transforming the data frame into a matrix\nFind edges filtering by those majority hscodes.\n\n\n\n\n\n\n\n\n4.1.2 Building heatmap"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-links-between-companies",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#visualizing-links-between-companies",
    "title": "Take-home_Ex03",
    "section": "4.2 Visualizing links between companies",
    "text": "4.2 Visualizing links between companies\n\n4.2.1 Build a network graph of those selected hscodes with most fishing weight:\n\nPrepare the data and build a graph.\n\n\n\n\n\n\n\n\nBasic network graph to see the whole picture.\n\n\n\n\n\nBuild a facet graph by years to see the change of network through years:\n\n\n\n\n\nBuild a facet network graph by hscode:\n\n\n\n\n\nBuild a facet_nodes graph by hscode to see the difference:\n\n\n\n\n\n\n4.2.2 Find communities\n\n\n\n\n\n4.2.3 Build interactive network graph.\nPrepare data for interactive network graph.\n\n\n\nBuild an interactive network graph for checking the position of each node."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#evaluate-the-sets-of-predicted-knowledge-graph-links-fisheye-has-provided",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#evaluate-the-sets-of-predicted-knowledge-graph-links-fisheye-has-provided",
    "title": "Take-home_Ex03",
    "section": "4.3 Evaluate the sets of predicted knowledge graph links FishEye has provided",
    "text": "4.3 Evaluate the sets of predicted knowledge graph links FishEye has provided\n\n4.3.1 Read provided json files:\nFirstly read all 12 files provided by Fisheye into one table.\n\n\n\n\n\n\n\n\n\nThen check number of edges by “hscode” and by “generagted_by” (here I renamed this column as “group”)\n\n\n\n\n\n4.3.2 Data wrangling for network graph:\n\n\n\n\n\n\n\n\n4.3.3 Visualize graph provided by Fisheye:\n\n\n\n\nFacet node graph by groups:\n\n\n\n\n\nFacet network graph by groups:\n\n\n\n\n\n\n\n\n\n\nConclusion:\n\n\n\nHere I will select “carp” group as the new set of links to add into mc2 graph, since from the facet nodes graph I can see this set of link got most and sparsest of nodes, indicating this set should be able to contribute the most to the original graph. At the same time, the facet network graph show not much difference between groups."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home_Ex02",
    "section": "",
    "text": "The country of Oceanus has sought FishEye International’s help in identifying companies possibly engaged in illegal, unreported, and unregulated (IUU) fishing. As part of the collaboration, FishEye’s analysts received import/export data for Oceanus’ marine and fishing industries. However, Oceanus has informed FishEye that the data is incomplete. To facilitate their analysis, FishEye transformed the trade data into a knowledge graph. Using this knowledge graph, they hope to understand business relationships, including finding links that will help them stop IUU fishing and protect marine species that are affected by it. FishEye analysts found that node-link diagrams gave them a good high-level overview of the knowledge graph. However, they are now looking for visualizations that provide more detail about patterns for entities in the knowledge graph. There are two main parts to this analysis.\nFirst, FishEye knows from past experience that companies caught fishing illegally will shut down but will then often start up again under a different name. FishEye wants your help to visualize temporal patterns so they can compare the activities of companies over time to determine if the companies have returned to their nefarious acts.\nSecond, FishEye has been using several tools, including artificial intelligence, to reason on the knowledge graph and suggest links that could extend the dataset. They have supplied 12 groups of link suggestions and need your help evaluating these groups to identify which tools are most reliable for completing the graph. FishEye is especially interested in identifying new temporal patterns or anomalies that are only present when new links are added.\n\n\n\n\nUse visual analytics to identify temporal patterns for individual entities and between entities in the knowledge graph FishEye created from trade records. Categorize the types of business relationship patterns you find. Limit your response to 600 words and 6 images.\nEvaluate the sets of predicted knowledge graph links FishEye has provided using visual analytics. Which sets are most reliable for completing the graph? Limit your response to 600 words and 6 images.\nIllustrate how your visual analytics approach can be used to identify new patterns and/or anomalies that are present in the knowledge graph after you have added the links you deemed reliable in question 2. Limit your response to 300 words and 4 images.\nIdentify companies that fit a pattern of illegal fishing. Use visualizations to support your conclusions and your confidence in them. Limit your response to 300 words and 4 images.\n\n\n\n\n\n\n\nNote:\n\n\n\nOnly Question 1 would be explored in this Exercise."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#find-the-nodes-and-edges",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#find-the-nodes-and-edges",
    "title": "Take-home_Ex02",
    "section": "3.1 Find the nodes and edges:",
    "text": "3.1 Find the nodes and edges:\n\n\nShow the code\n#view(mc2[[\"nodes\"]])\nmc2_nodes <- as_tibble(mc2$nodes) %>%\n  select(id, shpcountry, rcvcountry) %>%\n  distinct()\n\n\n\n\nShow the code\n#view(mc2[[\"links\"]])\nmc2_edges <- as_tibble(mc2$links) %>%\n  mutate(arrivaldate = ymd(arrivaldate)) %>%\n  mutate(year = year(arrivaldate)) %>%\n  select(source, target, weightkg, hscode, arrivaldate, year) %>%\n  drop_na() %>%\n  distinct()\n\nmc2_edges <-  mc2_edges %>%\n  mutate(from = with(mc2_nodes, id[match(mc2_edges$source, id)]))%>%\n  mutate(to = with(mc2_nodes, id[match(mc2_edges$target, id)])) %>%\n  distinct()\n\n\n\n\nShow the code\nglimpse(mc2_edges)\n\n\nRows: 5,190,407\nColumns: 8\n$ source      <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son's\", …\n$ target      <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Marine…\n$ weightkg    <int> 4780, 6125, 10855, 11250, 11165, 11290, 9000, 19490, 6865,…\n$ hscode      <chr> \"630630\", \"630630\", \"470710\", \"470710\", \"470710\", \"470710\"…\n$ arrivaldate <date> 2034-02-12, 2034-03-13, 2028-02-07, 2028-02-23, 2028-09-1…\n$ year        <dbl> 2034, 2034, 2028, 2028, 2028, 2028, 2028, 2028, 2028, 2028…\n$ from        <chr> \"AquaDelight Inc and Son's\", \"AquaDelight Inc and Son's\", …\n$ to          <chr> \"BaringoAmerica Marine Ges.m.b.H.\", \"BaringoAmerica Marine…\n\n\n\n\n\n\n\n\nNote:\n\n\n\nHere the ‘arrivaldate’ column of edges is treated as ‘chr’ datatype, would need to be changed to ‘date’ type. And a new column added to indicate years."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-data-distributions",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#checking-data-distributions",
    "title": "Take-home_Ex02",
    "section": "3.2 Checking data distributions:",
    "text": "3.2 Checking data distributions:\n\nDistribution of shipments and weight(kg) by year:\n\n\n\nShow the code\nshipping <- mc2_edges %>%\n         select(year, weightkg) %>%\n         group_by(year) %>%\n         summarise(count=n(),weightkg = sum(weightkg),kg_per_ship=weightkg/count)\n\nd <- highlight_key(shipping)\np1 <- ggplot(data=d, \n            aes(x = year,\n                y = count)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Year\") +\n  ylab(\"Count\")\n\np2 <- ggplot(data=d, \n            aes(x = year,\n                y = weightkg)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Year\") +\n  ylab(\"Weightkg\")\n\np3 <- ggplot(data=d, \n            aes(x = year,\n                y = kg_per_ship)) +\n  geom_bar(stat = \"identity\") +\n  xlab(\"Year\") +\n  ylab(\"average kg\")\n\nsubplot(ggplotly(p1),\n        ggplotly(p2),\n        ggplotly(p3),\n        shareX = TRUE,\n        nrows = 3,\n        titleY = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nNote:\n\n\n\nHere we can conclude from the distribution of shipment by year that the weight per shipment of year 2032 is significantly higher than other years, indicating possible abnormal fishing volume in this year. For later using, I will focus on those hscode with most number of shipment during 2032.\n\n\n\nCheck number of shipments and fishing weights in 2032 by hscode.\n\n\n\nShow the code\nhscode_count <-  mc2_edges %>%\n  filter(year==2032) %>%\n  select(hscode,weightkg) %>%\n  group_by(hscode) %>%\n  summarise(weightkg = sum(weightkg), count=n(), kg_per_ship=weightkg/count) %>%\n  distinct() %>%\n  arrange(desc(count))\nhscode_count\n\n\n# A tibble: 3,864 × 4\n   hscode   weightkg count kg_per_ship\n   <chr>       <dbl> <int>       <dbl>\n 1 306170  477204630 24772      19264.\n 2 940360  181475405 14794      12267.\n 3 870899  479390615 14255      33630.\n 4 611020   75241440 13321       5648.\n 5 950300  105203525 12274       8571.\n 6 304620  216078950  9958      21699.\n 7 870323 2578623605  9313     276884.\n 8 640299   86822135  8815       9849.\n 9 160414  477284410  8762      54472.\n10 940161   92760155  8528      10877.\n# ℹ 3,854 more rows\n\n\nShow the code\nhscode_topcount <- pull(head(hscode_count, 1),hscode)\nhscode_top_avekg <- pull(head(hscode_count%>%\n                                filter(count>1000) %>%\n                                arrange(desc(kg_per_ship)),1),hscode)\n\nsprintf(\"hscode with highest number of shipment: %s\", hscode_topcount)\n\n\n[1] \"hscode with highest number of shipment: 306170\"\n\n\nShow the code\nsprintf(\"hscode with highest weight(kg) per shipment: %s\", hscode_top_avekg)\n\n\n[1] \"hscode with highest weight(kg) per shipment: 721049\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-temporal-patterns-for-individual-entities-by-heatmap",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-temporal-patterns-for-individual-entities-by-heatmap",
    "title": "Take-home_Ex02",
    "section": "4.1 Visualizing temporal patterns for individual entities by heatmap",
    "text": "4.1 Visualizing temporal patterns for individual entities by heatmap\n\n4.1.1 Preparing data\nFilter out those id with more than 20K count of shipements and transform the data table into matrix.\n\n\nShow the code\nmc2_selected_id <- pull(mc2_edges %>% \n                                 select(source) %>% \n                                 group_by(source) %>%\n                                 summarize(count=n()) %>%\n                                 filter(count > 20000) %>%\n                                 distinct() %>%\n                                 rename(id=source), \n                               id)\n\nmc2_selected_companies <- mc2_edges %>%\n  filter(source %in% mc2_selected_id) %>%\n  select(source,year) %>%\n  group_by(source,year) %>%\n  summarize(shipment=n()) %>%\n  pivot_wider(names_from = year, values_from = shipment, values_fill = 0) \n\nrow.names(mc2_selected_companies) <- mc2_selected_companies$source\ncompanies_matrix <- data.matrix(mc2_selected_companies)\n\n\n\n\n4.1.2 Building heatmap\n\n\nShow the code\nheatmaply(normalize(companies_matrix[, -c(1, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 6,\n          fontsize_col = 6,\n          main=\"Companies' yearly trend of shipment counts\",\n          xlab = \"Year\",\n          ylab = \"Companies\"\n          )\n\n\n\n\n\n\n\n\n\n\n\n\nPlease mind here:\n\n\n\nThere are several companies have abrupt change in number of shipment through years. This could indicating abnormal like change of identity or abnormal fishing activities."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-networks",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualizing-networks",
    "title": "Take-home_Ex02",
    "section": "4.2 Visualizing networks",
    "text": "4.2 Visualizing networks\n\n4.2.1 Preparing data:\n\nFiltering edges by 2032 and set count as weights.\n\n\n\nShow the code\nmc2_edges_aggregated <- mc2_edges %>%\n  filter(year == 2032) %>%\n  group_by(source, target, hscode, from, to) %>%\n  summarise(weights = n(), ave_kg = sum(weightkg)/weights) %>%\n  filter(source!=target) %>%\n  ungroup()\n\nglimpse(mc2_edges_aggregated)\n\n\nRows: 152,980\nColumns: 7\n$ source  <chr> \" Direct Herring Company Transit\", \" Direct Herring Company Tr…\n$ target  <chr> \"Caracola Azul NV Nautical\", \"Caracola Azul NV Nautical\", \"Lim…\n$ hscode  <chr> \"160529\", \"306170\", \"841430\", \"330430\", \"392310\", \"392330\", \"3…\n$ from    <chr> \" Direct Herring Company Transit\", \" Direct Herring Company Tr…\n$ to      <chr> \"Caracola Azul NV Nautical\", \"Caracola Azul NV Nautical\", \"Lim…\n$ weights <int> 3, 2, 4, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 9, 9, 1, 1, 1, 1, 1, 2,…\n$ ave_kg  <dbl> 10745.000, 18422.500, 3725.000, 320.000, 6645.000, 6645.000, 1…\n\n\n\n\n4.2.2 Build network graph for hscode with highest shipment counts:\n\nFind edges of hscode equal to “306170”.\n\n\n\nShow the code\nmc2_edges_topcount <- mc2_edges_aggregated %>%\n  filter(hscode == hscode_topcount) %>%\n  group_by(from, to) %>%\n  summarise(weights = sum(weights)) %>%\n  filter(from!=to) %>%\n  filter(weights>1) %>%\n  ungroup\n\n\n\nExtract nodes. Check source and target companies, categorize them into “fisher” (nodes in “from” column) or “wholesaler” (nodes in “to” column).\n\n\n\nShow the code\nmc2_nodes_topcount <- rbind(mc2_edges_topcount %>%\n                                select(from)%>%\n                                rename(id=from) %>%\n                             mutate(group=\"fisher\"),\n                              mc2_edges_topcount %>%\n                                select(to)%>%\n                                rename(id=to) %>%\n                             mutate(group=\"wholesaler\")) %>% distinct()\n\n\n\nCheck any nodes been categorized into both “fisher” and “wholesaler”, mutate their group by higher weights.\n\n\n\nShow the code\nlookup_topcount <- mc2_nodes_topcount %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1) %>%\n  left_join(mc2_edges_topcount%>%\n              group_by(from)%>%\n              summarise(from_weights= sum(weights)),\n            by=c(\"id\"=\"from\")) %>%\n  left_join(mc2_edges_topcount%>%\n              group_by(to)%>%\n              summarise(to_weights=sum(weights)),\n            by=c(\"id\"=\"to\")) %>%\n  mutate(group=ifelse(from_weights >= to_weights, \"fisher\",\"wholesaler\"))\n\nmc2_nodes_topcount <- mc2_nodes_topcount %>%\n  left_join(lookup_topcount%>%select(id,group),by=\"id\") %>%\n  mutate(group = ifelse(!is.na(group.y),group.y,group.x)) %>%\n  select(-group.y,-group.x) %>%\n  distinct()\n\n\n\nCheck mutual-exclusiveness of category.\n\n\n\nShow the code\nmc2_nodes_topcount %>%\n  group_by(id) %>%\n  summarise(count=n())%>%\n  filter(count>1)\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id <chr>, count <int>\n\n\n\nBuild network graph.\n\n\n\nShow the code\nmc2_graph_topcount <- tbl_graph(nodes = mc2_nodes_topcount,\n                       edges = mc2_edges_topcount,\n                       directed = TRUE)\n\n\n\n\nShow the code\nmc2_graph_topcount %>%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(width=weights), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 2)) +\n  geom_node_point(aes(color=group, \n                  size = centrality_degree(mode = \"out\"))) + \n  theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNotice\n\n\n\nHere I used out-degree centrality as nodes’ size to focus more on shippers.\n\n\n\nCheck nodes with out-degree >= 20, those fisher transit products to many different nodes, they may conduct unreported fishing and try to hide it in splitted transactions.\n\n\n\nShow the code\nmc2_graph_topcount %>%\n    mutate(centrality_bet = centrality_degree(mode = \"out\")) %>%\n    filter(centrality_bet>=20) %>%\n    select(id,group) \n\n\n# A tbl_graph: 10 nodes and 0 edges\n#\n# A rooted forest with 10 trees\n#\n# A tibble: 10 × 2\n  id                                     group \n  <chr>                                  <chr> \n1 Balkan Cat ОАО Transport               fisher\n2 Blue Horizon Family &                  fisher\n3 CoralCove Foods AG Marine conservation fisher\n4 Daniel Ferry N.V. Transit              fisher\n5 Italian Sardines Ltd. Liability Co     fisher\n6 Lake Tana  & Son's                     fisher\n# ℹ 4 more rows\n#\n# A tibble: 0 × 3\n# ℹ 3 variables: from <int>, to <int>, weights <int>\n\n\n\nSince from the network graph above we can see that there are a lot of nodes in this network, here I will build interactive network graph with subset of data filtered by weights more than once a month (i.e. count of shipments >= 12).\n\n\n\nShow the code\nmc2_edges_topcount_sub <- mc2_edges_topcount %>%\n  filter(weights>12)\n\n\n\n\nShow the code\n#categarize nodes into 2 groups and make sure the group label is mutual exclusive\nmc2_nodes_topcount_sub <- rbind(mc2_edges_topcount_sub %>%\n                                select(from)%>%\n                                rename(id=from) %>%\n                             mutate(group=\"fisher\"),\n                              mc2_edges_topcount_sub %>%\n                                select(to)%>%\n                                rename(id=to) %>%\n                             mutate(group=\"wholesaler\")) %>% distinct()\n\nlookup_topcount_sub <- mc2_nodes_topcount_sub %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1) %>%\n  left_join(mc2_edges_topcount_sub%>%\n              group_by(from)%>%\n              summarise(from_weights= sum(weights)),\n            by=c(\"id\"=\"from\")) %>%\n  left_join(mc2_edges_topcount_sub%>%\n              group_by(to)%>%\n              summarise(to_weights=sum(weights)),\n            by=c(\"id\"=\"to\")) %>%\n  mutate(group=ifelse(from_weights >= to_weights, \"fisher\",\"wholesaler\"))\n\nmc2_nodes_topcount_sub <- mc2_nodes_topcount_sub %>%\n  left_join(lookup_topcount_sub%>%select(id,group),by=\"id\") %>%\n  mutate(group = ifelse(!is.na(group.y),group.y,group.x)) %>%\n  select(-group.y,-group.x) %>%\n  distinct()\n\n\n\n\nShow the code\n#build interactive network graph\nvisNetwork(mc2_nodes_topcount_sub,mc2_edges_topcount_sub) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\nThen let’s checkout those edges with only 1 shipment during the year:\n\n\n\nShow the code\nmc2_edges_topcount_1time <- mc2_edges_aggregated %>%\n  filter(hscode == hscode_topcount) %>%\n  group_by(from, to) %>%\n  summarise(weights = sum(weights)) %>%\n  filter(from!=to) %>%\n  filter(weights==1) %>%\n  ungroup\n\n\n\n\nShow the code\n#categarize nodes into 2 groups and make sure the group label is mutual exclusive\nmc2_nodes_topcount_1time <- rbind(mc2_edges_topcount_1time %>%\n                                select(from)%>%\n                                rename(id=from) %>%\n                             mutate(group=\"fisher\"),\n                              mc2_edges_topcount_1time %>%\n                                select(to)%>%\n                                rename(id=to) %>%\n                             mutate(group=\"wholesaler\")) %>% distinct()\n\nlookup_topcount_1time <- mc2_nodes_topcount_1time %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1) %>%\n  left_join(mc2_edges_topcount_1time%>%\n              group_by(from)%>%\n              summarise(from_weights= sum(weights)),\n            by=c(\"id\"=\"from\")) %>%\n  left_join(mc2_edges_topcount_1time%>%\n              group_by(to)%>%\n              summarise(to_weights=sum(weights)),\n            by=c(\"id\"=\"to\")) %>%\n  mutate(group=ifelse(from_weights >= to_weights, \"fisher\",\"wholesaler\"))\n\nmc2_nodes_topcount_1time <- mc2_nodes_topcount_1time %>%\n  left_join(lookup_topcount_1time%>%select(id,group),by=\"id\") %>%\n  mutate(group = ifelse(!is.na(group.y),group.y,group.x)) %>%\n  select(-group.y,-group.x) %>%\n  distinct()\n\n\n\n\nShow the code\n#build interactive network graph\nvisNetwork(mc2_nodes_topcount_1time,mc2_edges_topcount_1time) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlease mind here:\n\n\n\nHere from the graph of edges both with weights >=12 and weights == 1, we can see a basic pattern of transitions is that they are directed from multiple fishers to single wholesaler.\n\n\n\n\n4.2.3 Build network graph for hscodes with highest weight(kg) per shipment:\n\nFind edges of the hscodes.\n\n\n\nShow the code\nmc2_edges_topkg <- mc2_edges_aggregated %>%\n  filter(hscode == hscode_top_avekg) %>%\n  group_by(from, to) %>%\n  summarise(weights = sum(weights)) %>%\n  filter(from!=to) %>%\n#  filter(weights>1) %>%\n  ungroup\n\n\n\nExtract nodes. Check source and target companies, categorize them into “fisher” (nodes in “from” column) or “wholesaler” (nodes in “to” column).\n\n\n\nShow the code\nmc2_nodes_topkg <- rbind(mc2_edges_topkg %>%\n                                select(from)%>%\n                                rename(id=from) %>%\n                             mutate(group=\"fisher\"),\n                              mc2_edges_topkg %>%\n                                select(to)%>%\n                                rename(id=to) %>%\n                             mutate(group=\"wholesaler\")) %>% distinct()\n\nlookup_topkg <- mc2_nodes_topkg %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1) %>%\n  left_join(mc2_edges_topkg%>%\n              group_by(from)%>%\n              summarise(from_weights= sum(weights)),\n            by=c(\"id\"=\"from\")) %>%\n  left_join(mc2_edges_topkg%>%\n              group_by(to)%>%\n              summarise(to_weights=sum(weights)),\n            by=c(\"id\"=\"to\")) %>%\n  mutate(group=ifelse(from_weights >= to_weights, \"fisher\",\"wholesaler\"))\n\nmc2_nodes_topkg <- mc2_nodes_topkg %>%\n  left_join(lookup_topkg%>%select(id,group),by=\"id\") %>%\n  mutate(group = ifelse(!is.na(group.y),group.y,group.x)) %>%\n  select(-group.y,-group.x) %>%\n  distinct()\n\n\n\nCheck mutual-exclusiveness of category.\n\n\n\nShow the code\nmc2_nodes_topcount %>%\n  group_by(id) %>%\n  summarise(count=n())%>%\n  filter(count>1)\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id <chr>, count <int>\n\n\n\nBuild interactive network graph.\n\n\n\nShow the code\nvisNetwork(mc2_nodes_topkg,mc2_edges_topkg) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\nPlease mind here:\n\n\n\nHere we find the transition pattern is more of directed from one fisher to multiple wholesaler, this may due to the average weight(kg) of the product is relatively higher, so different parts of fish need to sale to different dealers."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#evaluate-the-sets-of-predicted-knowledge-graph-links-fisheye-has-provided",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#evaluate-the-sets-of-predicted-knowledge-graph-links-fisheye-has-provided",
    "title": "Take-home_Ex02",
    "section": "4.3 Evaluate the sets of predicted knowledge graph links FishEye has provided",
    "text": "4.3 Evaluate the sets of predicted knowledge graph links FishEye has provided\n\n4.3.1 Read provided json files:\nFirstly read all 12 files provided by Fisheye into one table.\n\n\nShow the code\nfiles <- list.files(path = \"data/bundles\", full.names = TRUE)\n\nfisheye_files <- lapply(files, fromJSON)\nfisheyedata <- lapply(fisheye_files, function(json) {\n  json$nodes\n  json$links\n})\n\nfisheye <- bind_rows(fisheyedata)\n\n\n\n\nShow the code\nfisheye_edges <- as_tibble(fisheye) %>%\n  mutate(arrivaldate = ymd(arrivaldate)) %>%\n  mutate(year = year(arrivaldate)) %>%\n  select(source, target, generated_by, hscode, arrivaldate, year,weightkg) %>%\n  rename(type = generated_by) %>%\n#  drop_na() %>%\n  distinct()\n\n\nThen check number of edges by year and by “generagted_by” (here I renamed this column as “group”)\n\n\nShow the code\nfisheye_count <-  fisheye_edges %>%\n  select(year,type,weightkg) %>%\n  group_by(year,type) %>%\n  summarise(count= n(),weightkg = sum(weightkg)) %>%\n  arrange(year)\n\nfisheye_count\n\n\n# A tibble: 15 × 4\n# Groups:   year [3]\n    year type          count weightkg\n   <dbl> <chr>         <int>    <int>\n 1  2033 tuna              3       NA\n 2  2034 carp            165  5270060\n 3  2034 catfish         253       NA\n 4  2034 chub_mackerel   153  3347745\n 5  2034 cod2              4   102760\n 6  2034 herring         154  8395075\n 7  2034 lichen           23   146565\n 8  2034 mackerel        134       NA\n 9  2034 pollock         103  2700860\n10  2034 salmon           13   199955\n11  2034 salmon_wgl       92  1924855\n12  2034 shark            19   114745\n13  2034 tuna             52       NA\n14  2035 catfish          24       NA\n15  2035 mackerel         64       NA\n\n\n\n\n4.3.2 Data wrangling for network graph:\n\n\nShow the code\nfisheye_edges_aggregated <- fisheye_edges %>%\n  group_by(source, target, hscode, year, type) %>%\n    summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup()\n\n\n\n\nShow the code\nfisheye_nodes_extracted <- rbind(fisheye_edges_aggregated %>%\n  select(source,type) %>%\n  rename(id = source), \n  fisheye_edges_aggregated %>%\n  select(target,type) %>%\n  rename(id = target)) %>%\n  distinct()\n\n\n\n\n4.3.3 Visualize graph provided by Fisheye:\n\n\nShow the code\nfisheye_graph <- tbl_graph(nodes = fisheye_nodes_extracted,\n                       edges = fisheye_edges_aggregated,\n                       directed = TRUE)\n\n\n\n\nShow the code\nset_graph_style() \n\nggraph(fisheye_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(linewidth=weights), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(), size = 0.5) +\n  theme(legend.position = 'bottom')+ \n  facet_nodes(~type)+\n  th_foreground(foreground = \"grey90\",  \n                border = TRUE)  \n\n\n\n\n\n\n\n\n\n\n\nMinding Here:\n\n\n\nI will firstly choose those set of links with more nodes. The final choice can be made only after we saw the complementary effect after we add those links to original network.\n\n\n\nBuild network graph for selected set of links:\n\n\n\nShow the code\nselected_links <- c('carp','catfish','chub_mackerel','herring','mackerel','pollock','salmon_wgl')\n\nfisheye_selected_edges <- fisheye_edges_aggregated %>%\n  filter(type == selected_links) %>%\n  rename(from = source) %>%\n  rename(to = target) %>%\n  filter(from != to) %>%\n  distinct()\n\nfisheye_selected_nodes <- rbind(fisheye_selected_edges %>%\n                                select(from)%>%\n                                rename(id=from)%>%\n                                  mutate(group = \"fisher\"),\n                                fisheye_selected_edges %>%\n                                select(to)%>%\n                                rename(id=to)%>%\n                                  mutate(group = \"wholesaler\")) %>% distinct()\n\n\n\n\nShow the code\nfisheye_lookup <- fisheye_selected_nodes %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1) %>%\n  left_join(fisheye_selected_edges%>%\n              group_by(from)%>%\n              summarise(from_weights= sum(weights)),\n            by=c(\"id\"=\"from\")) %>%\n  left_join(mc2_edges_hscode3%>%\n              group_by(to)%>%\n              summarise(to_weights=sum(weights)),\n            by=c(\"id\"=\"to\")) %>%\n  mutate(group=ifelse(from_weights >= to_weights | is.na(to_weights), \"fisher\",\"wholesaler\"))\n\nfisheye_selected_nodes <- fisheye_selected_nodes %>%\n  left_join(fisheye_lookup%>%select(id,group),by=\"id\") %>%\n  mutate(group = ifelse(!is.na(group.y),group.y,group.x)) %>%\n  select(-group.y,-group.x) %>%\n  distinct()\n\n\n\n\nShow the code\nfisheye_selected_nodes %>%\n  group_by(id) %>%\n  summarise(count=n()) %>%\n  filter(count>1)\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: id <chr>, count <int>\n\n\n\n\nShow the code\nfisheye_selected_graph <- tbl_graph(nodes = fisheye_selected_nodes,\n                       edges = fisheye_selected_edges,\n                       directed = TRUE)\ncentrality <- degree(fisheye_selected_graph)\nvisNetwork(fisheye_selected_nodes,fisheye_selected_edges) %>%\n  visIgraphLayout(layout = \"layout_with_kk\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class_Ex04",
    "section": "",
    "text": "Load packages and data:\n\npacman::p_load(rstatix, gt, patchwork, tidyverse)\n\nexam_data <-read_csv(\"data/Exam_data.csv\")\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data,\n      aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSome emphasizing notice\n\n\n\nqq <- ggplot(exam_data,\n             aes(sample=ENGLISH)) +\n  stat_qq() +\n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t, tmp)\ntable_png <- png::readPNG(tmp, native = TRUE)\n\nqq + table_png"
  }
]